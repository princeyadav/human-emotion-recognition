{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELPATH = './models/model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "width, height = 48, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = data['pixels'].tolist() \n",
    "faces = []\n",
    "for pixel_sequence in pixels:\n",
    "    face = [int(pixel) for pixel in pixel_sequence.split(' ')] \n",
    "    face = np.asarray(face).reshape(width, height)\n",
    "    \n",
    "    faces.append(face.astype('float32'))\n",
    "\n",
    "faces = np.asarray(faces)\n",
    "faces = np.expand_dims(faces, -1)\n",
    "\n",
    "emotions = pd.get_dummies(data['emotion']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1), data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(2*2*2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2*2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 46, 46, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 23, 23, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 23, 23, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 23, 23, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 23, 23, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 11, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 5, 5, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 5,905,863\n",
      "Trainable params: 5,902,151\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29068 samples, validate on 3589 samples\n",
      "Epoch 1/100\n",
      "29068/29068 [==============================] - 69s 2ms/step - loss: 2.0309 - accuracy: 0.2121 - val_loss: 1.8110 - val_accuracy: 0.2407\n",
      "Epoch 2/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 1.8222 - accuracy: 0.2530 - val_loss: 1.7427 - val_accuracy: 0.2884\n",
      "Epoch 3/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 1.7535 - accuracy: 0.2894 - val_loss: 1.8621 - val_accuracy: 0.2329\n",
      "Epoch 4/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 1.6669 - accuracy: 0.3366 - val_loss: 1.6534 - val_accuracy: 0.3580\n",
      "Epoch 5/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 1.5723 - accuracy: 0.3832 - val_loss: 1.5619 - val_accuracy: 0.3675\n",
      "Epoch 6/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 1.4921 - accuracy: 0.4142 - val_loss: 1.4895 - val_accuracy: 0.3987\n",
      "Epoch 7/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 1.4376 - accuracy: 0.4484 - val_loss: 1.3709 - val_accuracy: 0.4687\n",
      "Epoch 8/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 1.3933 - accuracy: 0.4702 - val_loss: 1.2671 - val_accuracy: 0.5124\n",
      "Epoch 9/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 1.3608 - accuracy: 0.4874 - val_loss: 1.2982 - val_accuracy: 0.4990\n",
      "Epoch 10/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 1.3263 - accuracy: 0.5015 - val_loss: 1.2596 - val_accuracy: 0.5202\n",
      "Epoch 11/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 1.2890 - accuracy: 0.5187 - val_loss: 1.3318 - val_accuracy: 0.5001\n",
      "Epoch 12/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 1.2731 - accuracy: 0.5284 - val_loss: 1.4942 - val_accuracy: 0.4425\n",
      "Epoch 13/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 1.2528 - accuracy: 0.5348 - val_loss: 1.3721 - val_accuracy: 0.4882\n",
      "Epoch 14/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 1.2201 - accuracy: 0.5515 - val_loss: 1.1499 - val_accuracy: 0.5653\n",
      "Epoch 15/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 1.1969 - accuracy: 0.5576 - val_loss: 1.1878 - val_accuracy: 0.5651\n",
      "Epoch 16/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 1.1737 - accuracy: 0.5655 - val_loss: 1.1689 - val_accuracy: 0.5748\n",
      "Epoch 17/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 1.1495 - accuracy: 0.5817 - val_loss: 1.1476 - val_accuracy: 0.5729\n",
      "Epoch 18/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 1.1293 - accuracy: 0.5884 - val_loss: 1.3041 - val_accuracy: 0.5091\n",
      "Epoch 19/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 1.1135 - accuracy: 0.5936 - val_loss: 1.0900 - val_accuracy: 0.5946\n",
      "Epoch 20/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 1.0829 - accuracy: 0.6063 - val_loss: 1.1132 - val_accuracy: 0.5857\n",
      "Epoch 21/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 1.0687 - accuracy: 0.6114 - val_loss: 1.1607 - val_accuracy: 0.5528\n",
      "Epoch 22/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 1.0492 - accuracy: 0.6230 - val_loss: 1.1290 - val_accuracy: 0.5907\n",
      "Epoch 23/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 1.0226 - accuracy: 0.6298 - val_loss: 1.0896 - val_accuracy: 0.6043\n",
      "Epoch 24/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 1.0040 - accuracy: 0.6359 - val_loss: 1.0642 - val_accuracy: 0.6116\n",
      "Epoch 25/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.9882 - accuracy: 0.6413 - val_loss: 1.0485 - val_accuracy: 0.6219\n",
      "Epoch 26/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.9675 - accuracy: 0.6501 - val_loss: 1.0479 - val_accuracy: 0.6147\n",
      "Epoch 27/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.9561 - accuracy: 0.6543 - val_loss: 1.1348 - val_accuracy: 0.5882\n",
      "Epoch 28/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.9405 - accuracy: 0.6625 - val_loss: 1.0562 - val_accuracy: 0.6199\n",
      "Epoch 29/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.9138 - accuracy: 0.6681 - val_loss: 1.0313 - val_accuracy: 0.6319\n",
      "Epoch 30/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.8983 - accuracy: 0.6773 - val_loss: 1.0458 - val_accuracy: 0.6166\n",
      "Epoch 31/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.8912 - accuracy: 0.6807 - val_loss: 1.0571 - val_accuracy: 0.6160\n",
      "Epoch 32/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.8762 - accuracy: 0.6864 - val_loss: 1.0857 - val_accuracy: 0.6127\n",
      "Epoch 33/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.8606 - accuracy: 0.6950 - val_loss: 1.0695 - val_accuracy: 0.6222\n",
      "Epoch 34/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.8432 - accuracy: 0.6970 - val_loss: 1.0967 - val_accuracy: 0.6180\n",
      "Epoch 35/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.8262 - accuracy: 0.7028 - val_loss: 1.0801 - val_accuracy: 0.6166\n",
      "Epoch 36/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.8175 - accuracy: 0.7115 - val_loss: 1.0944 - val_accuracy: 0.6258\n",
      "Epoch 37/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.7990 - accuracy: 0.7146 - val_loss: 1.0916 - val_accuracy: 0.6414\n",
      "Epoch 38/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.7898 - accuracy: 0.7203 - val_loss: 1.1603 - val_accuracy: 0.6027\n",
      "Epoch 39/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.7753 - accuracy: 0.7235 - val_loss: 1.0725 - val_accuracy: 0.6383\n",
      "Epoch 40/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.7625 - accuracy: 0.7270 - val_loss: 1.1566 - val_accuracy: 0.6230\n",
      "Epoch 41/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.7474 - accuracy: 0.7347 - val_loss: 1.0638 - val_accuracy: 0.6314\n",
      "Epoch 42/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.7342 - accuracy: 0.7392 - val_loss: 1.0487 - val_accuracy: 0.6361\n",
      "Epoch 43/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.7162 - accuracy: 0.7455 - val_loss: 1.1750 - val_accuracy: 0.6244\n",
      "Epoch 44/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.7199 - accuracy: 0.7451 - val_loss: 1.0969 - val_accuracy: 0.6436\n",
      "Epoch 45/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.6899 - accuracy: 0.7620 - val_loss: 1.0793 - val_accuracy: 0.6467\n",
      "Epoch 46/100\n",
      "29068/29068 [==============================] - 61s 2ms/step - loss: 0.6851 - accuracy: 0.7615 - val_loss: 1.1111 - val_accuracy: 0.6275\n",
      "Epoch 47/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.6807 - accuracy: 0.7646 - val_loss: 1.0772 - val_accuracy: 0.6475\n",
      "Epoch 48/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.6706 - accuracy: 0.7660 - val_loss: 1.0815 - val_accuracy: 0.6386\n",
      "Epoch 49/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.6493 - accuracy: 0.7774 - val_loss: 1.1130 - val_accuracy: 0.6492\n",
      "Epoch 50/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.6508 - accuracy: 0.7761 - val_loss: 1.1348 - val_accuracy: 0.6406\n",
      "Epoch 51/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.6277 - accuracy: 0.7855 - val_loss: 1.1149 - val_accuracy: 0.6486\n",
      "Epoch 52/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.6209 - accuracy: 0.7858 - val_loss: 1.1495 - val_accuracy: 0.6414\n",
      "Epoch 53/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.6166 - accuracy: 0.7873 - val_loss: 1.1269 - val_accuracy: 0.6353\n",
      "Epoch 54/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.6094 - accuracy: 0.7872 - val_loss: 1.1296 - val_accuracy: 0.6489\n",
      "Epoch 55/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.5942 - accuracy: 0.7958 - val_loss: 1.1430 - val_accuracy: 0.6495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.5803 - accuracy: 0.8017 - val_loss: 1.1939 - val_accuracy: 0.6408\n",
      "Epoch 57/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.5838 - accuracy: 0.8019 - val_loss: 1.1443 - val_accuracy: 0.6484\n",
      "Epoch 58/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.5626 - accuracy: 0.8095 - val_loss: 1.1496 - val_accuracy: 0.6400\n",
      "Epoch 59/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.5518 - accuracy: 0.8104 - val_loss: 1.1495 - val_accuracy: 0.6473\n",
      "Epoch 60/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.5410 - accuracy: 0.8162 - val_loss: 1.1601 - val_accuracy: 0.6453\n",
      "Epoch 61/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.5431 - accuracy: 0.8139 - val_loss: 1.2098 - val_accuracy: 0.6230\n",
      "Epoch 62/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.5343 - accuracy: 0.8214 - val_loss: 1.1777 - val_accuracy: 0.6450\n",
      "Epoch 63/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.5287 - accuracy: 0.8223 - val_loss: 1.2084 - val_accuracy: 0.6500\n",
      "Epoch 64/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.5120 - accuracy: 0.8257 - val_loss: 1.1857 - val_accuracy: 0.6528\n",
      "Epoch 65/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.5091 - accuracy: 0.8291 - val_loss: 1.1799 - val_accuracy: 0.6523\n",
      "Epoch 66/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.5006 - accuracy: 0.8321 - val_loss: 1.2483 - val_accuracy: 0.6514\n",
      "Epoch 67/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.4950 - accuracy: 0.8351 - val_loss: 1.2794 - val_accuracy: 0.6464\n",
      "Epoch 68/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.4803 - accuracy: 0.8373 - val_loss: 1.3788 - val_accuracy: 0.6280\n",
      "Epoch 69/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.4747 - accuracy: 0.8403 - val_loss: 1.2716 - val_accuracy: 0.6484\n",
      "Epoch 70/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.4651 - accuracy: 0.8443 - val_loss: 1.2004 - val_accuracy: 0.6392\n",
      "Epoch 71/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.4699 - accuracy: 0.8438 - val_loss: 1.2807 - val_accuracy: 0.6436\n",
      "Epoch 72/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.4637 - accuracy: 0.8453 - val_loss: 1.2098 - val_accuracy: 0.6461\n",
      "Epoch 73/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.4500 - accuracy: 0.8527 - val_loss: 1.2380 - val_accuracy: 0.6570\n",
      "Epoch 74/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.4387 - accuracy: 0.8535 - val_loss: 1.3112 - val_accuracy: 0.6542\n",
      "Epoch 75/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.4362 - accuracy: 0.8544 - val_loss: 1.2526 - val_accuracy: 0.6445\n",
      "Epoch 76/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.4309 - accuracy: 0.8583 - val_loss: 1.3083 - val_accuracy: 0.6464\n",
      "Epoch 77/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.4336 - accuracy: 0.8581 - val_loss: 1.3767 - val_accuracy: 0.6422\n",
      "Epoch 78/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.4295 - accuracy: 0.8603 - val_loss: 1.3071 - val_accuracy: 0.6528\n",
      "Epoch 79/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.4238 - accuracy: 0.8627 - val_loss: 1.2899 - val_accuracy: 0.6556\n",
      "Epoch 80/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.4174 - accuracy: 0.8636 - val_loss: 1.2918 - val_accuracy: 0.6520\n",
      "Epoch 81/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.4045 - accuracy: 0.8681 - val_loss: 1.2611 - val_accuracy: 0.6548\n",
      "Epoch 82/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3999 - accuracy: 0.8682 - val_loss: 1.3162 - val_accuracy: 0.6473\n",
      "Epoch 83/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3980 - accuracy: 0.8676 - val_loss: 1.3842 - val_accuracy: 0.6439\n",
      "Epoch 84/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3999 - accuracy: 0.8695 - val_loss: 1.3669 - val_accuracy: 0.6503\n",
      "Epoch 85/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3872 - accuracy: 0.8742 - val_loss: 1.3513 - val_accuracy: 0.6520\n",
      "Epoch 86/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3847 - accuracy: 0.8753 - val_loss: 1.4162 - val_accuracy: 0.6475\n",
      "Epoch 87/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3786 - accuracy: 0.8792 - val_loss: 1.3461 - val_accuracy: 0.6350\n",
      "Epoch 88/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3728 - accuracy: 0.8794 - val_loss: 1.3968 - val_accuracy: 0.6537\n",
      "Epoch 89/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3694 - accuracy: 0.8799 - val_loss: 1.4041 - val_accuracy: 0.6473\n",
      "Epoch 90/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3624 - accuracy: 0.8836 - val_loss: 1.4026 - val_accuracy: 0.6333\n",
      "Epoch 91/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3702 - accuracy: 0.8805 - val_loss: 1.3398 - val_accuracy: 0.6517\n",
      "Epoch 92/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3578 - accuracy: 0.8864 - val_loss: 1.3385 - val_accuracy: 0.6520\n",
      "Epoch 93/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3571 - accuracy: 0.8875 - val_loss: 1.3869 - val_accuracy: 0.6498\n",
      "Epoch 94/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3504 - accuracy: 0.8883 - val_loss: 1.3968 - val_accuracy: 0.6506\n",
      "Epoch 95/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3429 - accuracy: 0.8901 - val_loss: 1.4307 - val_accuracy: 0.6464\n",
      "Epoch 96/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3407 - accuracy: 0.8897 - val_loss: 1.5552 - val_accuracy: 0.6422\n",
      "Epoch 97/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3422 - accuracy: 0.8909 - val_loss: 1.4035 - val_accuracy: 0.6576\n",
      "Epoch 98/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3313 - accuracy: 0.8939 - val_loss: 1.4094 - val_accuracy: 0.6464\n",
      "Epoch 99/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3343 - accuracy: 0.8952 - val_loss: 1.3344 - val_accuracy: 0.6517\n",
      "Epoch 100/100\n",
      "29068/29068 [==============================] - 60s 2ms/step - loss: 0.3211 - accuracy: 0.9013 - val_loss: 1.4039 - val_accuracy: 0.6601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2914593b688>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X_train), np.array(y_train),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(np.array(X_test), np.array(y_test)),\n",
    "          shuffle=True,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
